Small Language Model (SLM) for Book-Based Question Answering ğŸ“–ğŸ¤–

ğŸš€ A lightweight and efficient language model for retrieving relevant passages from books and answering user queries.

ğŸ”¹ Features

âœ… Dynamic Passage Addition â€“ Users can add book passages via API.âœ… Fast & Accurate Retrieval â€“ Uses FAISS indexing and MiniLM embeddings.âœ… Ready-to-Use â€“ No additional training required.âœ… Scalable & Efficient â€“ Handles large datasets with optimized search.

ğŸ“Œ How It Works

1ï¸âƒ£ Users upload book passages via /add_passages API.2ï¸âƒ£ The system encodes passages into vector embeddings.3ï¸âƒ£ FAISS retrieves the most relevant passage for a given question.4ï¸âƒ£ Returns the best-matching passage as the answer.

ğŸ”§ Installation & Setup

1. Clone the Repository

git clone https://github.com/your-repo/slm-book-qa.git
cd slm-book-qa

2. Install Dependencies

pip install -r requirements.txt

3. Run the API Server

uvicorn app:app --reload

ğŸ“ Usage

1. Add Book Passages

curl -X POST "http://127.0.0.1:8000/add_passages" -H "Content-Type: application/json" -d '{"passages": ["John is a detective solving crimes.", "The city has flying cars."]}'

2. Ask a Question

curl "http://127.0.0.1:8000/ask?question=Who is John?"

Expected Output

{"retrieved_passage": "John is a detective solving crimes."}

ğŸ›  Technologies Used

SentenceTransformers (MiniLM) for text embeddings

FAISS for efficient passage retrieval

FastAPI for API handling

Python (NumPy, Torch)

ğŸ“Œ Key Learnings & Observations

âœ… Efficient retrieval with FAISS improves query performance.âœ… No fine-tuning required, making it lightweight and fast.âœ… Highly scalable â€“ Can handle thousands of book passages.

ğŸ“ Contributing

Want to contribute? Open an issue or submit a pull request!
